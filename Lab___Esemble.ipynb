{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the data\n",
        "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
        "spaceship.head()\n",
        "\n",
        "# Step 2: Handle missing data\n",
        "# We'll use SimpleImputer to fill missing values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Impute missing values for the relevant columns\n",
        "spaceship['HomePlanet'] = imputer.fit_transform(spaceship[['HomePlanet']])\n",
        "spaceship['CryoSleep'] = imputer.fit_transform(spaceship[['CryoSleep']])\n",
        "spaceship['Destination'] = imputer.fit_transform(spaceship[['Destination']])\n",
        "spaceship['VIP'] = imputer.fit_transform(spaceship[['VIP']])\n",
        "spaceship['Age'] = imputer.fit_transform(spaceship[['Age']])\n",
        "spaceship['RoomService'] = imputer.fit_transform(spaceship[['RoomService']])\n",
        "spaceship['FoodCourt'] = imputer.fit_transform(spaceship[['FoodCourt']])\n",
        "spaceship['ShoppingMall'] = imputer.fit_transform(spaceship[['ShoppingMall']])\n",
        "spaceship['Spa'] = imputer.fit_transform(spaceship[['Spa']])\n",
        "spaceship['VRDeck'] = imputer.fit_transform(spaceship[['VRDeck']])\n",
        "\n",
        "# Step 3: Convert categorical columns to numerical (encoding)\n",
        "spaceship = pd.get_dummies(spaceship, drop_first=True)\n",
        "\n",
        "# Step 4: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "scaled_columns = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "spaceship[scaled_columns] = scaler.fit_transform(spaceship[scaled_columns])\n",
        "\n",
        "# Check the data after preprocessing\n",
        "spaceship.head()\n",
        "\n",
        "# Step 5: Train-test split\n",
        "X = spaceship.drop(['PassengerId', 'Name', 'Transported'], axis=1)  # Features\n",
        "y = spaceship['Transported']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shape of the resulting datasets\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# Bagging (using DecisionTreeClassifier as base estimator)\n",
        "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the accuracy\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "print(f\"Bagging Model Accuracy: {accuracy_bagging:.4f}\")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the accuracy\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Model Accuracy: {accuracy_rf:.4f}\")\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the accuracy\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(f\"Gradient Boosting Model Accuracy: {accuracy_gb:.4f}\")\n",
        "\n",
        "# AdaBoost Classifier\n",
        "ab_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ab_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the accuracy\n",
        "y_pred_ab = ab_model.predict(X_test)\n",
        "accuracy_ab = accuracy_score(y_test, y_pred_ab)\n",
        "print(f\"AdaBoost Model Accuracy: {accuracy_ab:.4f}\")\n",
        "\n",
        "# Comparing the results\n",
        "results = {\n",
        "    'Bagging': accuracy_bagging,\n",
        "    'Random Forest': accuracy_rf,\n",
        "    'Gradient Boosting': accuracy_gb,\n",
        "    'AdaBoost': accuracy_ab\n",
        "}\n",
        "\n",
        "# Identify the best performing model\n",
        "best_model = max(results, key=results.get)\n",
        "best_accuracy = results[best_model]\n",
        "\n",
        "# Display the comparison\n",
        "print(\"\\nModel Comparison:\")\n",
        "for model, accuracy in results.items():\n",
        "    print(f\"{model}: {accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nThe best model is: {best_model} with accuracy {best_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "E2pLQSKP3LEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}